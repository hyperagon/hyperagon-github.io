+++
title = "Llama.cpp"
summary = "How to get Llama up and running?"
date = 2024-12-18T08:10:34+01:00
draft = false
tags = ['AI',]
+++
I've watched a lot about **AI** but only saw random results until I decided to go as low-level as possible.

For starters grab a copy of [Llama Cpp](https://github.com/ggerganov/llama.cpp.git) with `git clone https://github.com/ggerganov/llama.cpp.git`.
Then compile it (you'll need [CMake](https://cmake.org/)) with `cd llama.cpp/; cmake -B build; cmake --build build --config Release`.

Now just get any **GGUF** model from [Huggingface](https://huggingface.co/models?library=gguf), download it and use it with `./build/bin/llama-cli -m your_model.gguf -p "I believe the meaning of life is" -n 128`

or, if your computer can take it, talk with it using `./build/bin/llama-cli -m your_model.gguf -cnv -n 128`.
